

\section{Numerics}
\subsection{Discretization}
\subsubsection{1st Derivative}

$$g'(x)\approx \frac{g(x+\Delta x)-g(x)}{\Delta x} \qquad\qquad \text{or}
\qquad\qquad \boxed{g'(x)\approx \frac{g(x+\Delta x)-g(x-\Delta x)}{2\Delta
x}}\qquad \text{(Central Difference: Better Quality)}$$

\subsubsection{2nd Derivative}
$\boxed{g''(x)\approx \frac{g(x-\Delta x)-2 g(x) + g(x+ \Delta x)}{\Delta x^2}}$ is the same for the second (better quality) version.

\subsection{FDM}
\textbf{TIP:} Derive the equation system by hand for non-zero initial conditions, reduces the chance of errors.
\subsubsection{Basic Equation: $-u''(x)=f(x)$}
$ A^{(n)} \tilde{u}^{(n)} =f^{(n)}   $\\
$A^{(n)}= \frac{1}{\Delta x^2} \tridiag_{n-1} (-1,2,-1) = \frac{1}{\Delta x^2}
  \begin{bmatrix}
             2& -1 & 0 & \ldots \\
             -1& 2 & -1 & \ldots \\
              0& -1 & 2 & \ldots \\
              0& 0 & -1 & \ldots \\
             \ldots
           \end{bmatrix}$\qquad (an $(n-1)\times(n-1)$ matrix)\\
Boundary: $u(0)= a \qquad u(n)=b $ \qquad
$A^{(n)}\tilde{u}^{(n)} =\begin{bmatrix}
             f(x_1^{(n)}) + \dfrac{a}{\Delta x^2} \\
             f(x_2^{(n)}) \\
             \vdots  \\
             f(x_{(n-1)}^{(n)}) + \dfrac{b}{\Delta x^2}
           \end{bmatrix} $\\

\subsubsection{Basic Equation: $T''(x) -  h T(x) = T_A$}
$-T'' + h T(x) = h T_A$\\
$A^{(n)}= \frac{1}{\Delta x^2} \tridiag_{n-1}
(-1,2+h\Delta x^2,-1) = \frac{1}{\Delta x^2}
  \begin{bmatrix}
             2+h\Delta x^2& -1 & 0 & \ldots \\
             -1& 2+h\Delta x^2 & -1 & \ldots \\
              0& -1 & 2+h\Delta x^2 & \ldots \\
              0& 0 & -1 & \ldots \\
             \ldots
           \end{bmatrix} $

\subsubsection{Example Homework 7}
Given: $ u''(x)=4(u(x)-x) $ with boundary values $ u(0)=0 $ and $ u(1)=2 $ with $\Delta x=1/3$.
\\
To find: $ \tilde{u}(\frac{1}{3}) $ and $ \tilde{u}(\frac{2}{3}) $
\\
Solution: Substitute the derivative of $ u'' $ into the equation, see above, giving the general equation $ \frac{u(x-\Delta x)-2 u(x) + u(x+ \Delta x)}{\Delta x^2} =4 (u(x)-x) $, for points P1 and P2, this yields:
\\
P1: $ \frac{0-2 \tilde{u}(\frac{1}{3}) + \tilde{u}(\frac{2}{3})}{(\frac{1}{3})^2} =4(\tilde{u}(\frac{1}{3})-\frac{1}{3}) $
\qquad \qquad
P2: $ \frac{\tilde{u}(\frac{1}{3})-2 \tilde{u}(\frac{2}{3}) + 2}{(\frac{1}{3})^2} =4(\tilde{u}(\frac{2}{3})-\frac{2}{3}) $
\\
Now solve the system of equations to get $ \tilde{u}(\frac{1}{3}) $ and $ \tilde{u}(\frac{2}{3}) $

\subsection{Convergence}
A model is convergent if, as $n\rightarrow\infty$, the approximation $\tilde{u}$ and $u$ coincide.\\

$\boxed{||v||_{\Delta x}=\sqrt{\Delta x (v_1^2+v_2^2 + \ldots v_{n-1}^2)}= \sqrt{\Delta
x}||v||}$\\
It converges if: $\lim\limits_{n\to \infty
}||\tilde{u}^{(n)}-u^{(n)}||_{1/n}=\sqrt{\frac{1}{n}}||\tilde{u}^{(n)}-u^{(n)}||=\sqrt{\frac{1}{n}}\sqrt{(\tilde{u}_1-u_1)^2
+ \ldots + (\tilde{u}_{n-1}-u_{n-1})}=0$\\

\subsection{Consistency}
A model is consistent when the model aligns with reality through simplification.

\subsubsection{Residue}
Exact: $A^{(n)}\cdot \tilde{u}^{(n)}-f^{(n)}=0$\\
Residue: $A^{(n)}\cdot (u^{(n)}-\tilde{u}^{(n)})=r^{(n)}$

An approximation method is consistent if $\boxed{\lim\limits_{n\rightarrow \infty}||r^{(n)}||_{1/n}=0}$ holds.\\

Consistency is a necessary but not sufficient condition for the convergence of a method.

\subsubsection{Taylor}
$g(x)= \sum\limits_{k=0}^n\frac{1}{k!} g^{(k)}(x_0)(x-x_0)^k +
\frac{1}{(n+1)!}g^{(n+1)}(\xi)(x-x_0)^{n+1}$ = Taylor
Approximation Polynomial  + Lagrange Remainder\\
$\xi \longmapsto [x_0 < \xi < x]$\\

Alternative
$ f(x_0+h)=f(x_0)+f'(x_0)\frac{h}{1!}+...+f^{(n)}(x_0)\frac{h^n}{n!}+R_n(h) $ where $ h = x - x_0 $

\subsubsection{Forward/Backward Difference}
$g'(x) - \frac{g(x+\Delta x) + g(x)}{\Delta x}= O(\Delta x) =
\frac{g''(\xi)}{2}\Delta x \Rightarrow$  1st Order

\subsubsection{Central Difference}
$g'(x) - \frac{g(x+\Delta x) + g(x-\Delta x)}{2\Delta x}= O(\Delta x^2) =
\frac{g'''(\xi_1) + g'''(\xi_2)}{12}\Delta x^2 \Rightarrow$ 2nd Order

\subsubsection{2nd Derivative}
$g''(x) - \frac{g(x+\Delta x) -2 g(x)+ g(x-\Delta x)}{2\Delta x}= O(\Delta x^2) =
\frac{g''''(\xi_1) + g''''(\xi_2)}{24}\Delta x^2 \Rightarrow$ 2nd Order\\
\\
Global consistency error for 2nd Derivative: $||r^{(n)}||_{1/n}\leq \frac 1{12}\max\limits_{\xi\in[0,1]}|f''(\xi)|\cdot \Delta x^2$

\subsection{Stability}
The stability of a matrix can be determined through its norm $||A||_*$.\\

It holds: $||A||_*=\max\limits_{||x||_*=1}||A\cdot x||_*$\qquad$||A\cdot x||_*\leq||A||~||x||_*$\\

An approximation method is stable if, independent of the constant $C$, the following holds:
$\boxed{||{A^{(n)}}^{-1}||_{1/n}\leq C}$\\

Determining $||A||$ is generally not easy, so $||A||$ is often determined through the diagonalization of A.

$y=A\cdot x\qquad\Rightarrow\qquad\tilde{y}=D\cdot\tilde{x}$\qquad with\qquad $D=\begin{bmatrix}\lambda_1&&\\&\ddots&\\&&\lambda_n\end{bmatrix}$\\

It holds $TAT^T=D$, where T is the transformation matrix from $x$ coordinate system to $\tilde{x}$ coordinate system. $T$ is orthogonal.
The diagonal elements $\lambda_1,\ldots,\lambda_n$ are also called eigenvalues.\\

It follows: $\boxed{||A||=\max\limits_{k}|\lambda_k|}$ and $\boxed{||A^{-1}||=\{\min\limits_{k}|\lambda_k|\}^{-1}}$\\

Determining eigenvalues: $\boxed{\det(A-\lambda I)=|A-\lambda I|=0}\qquad \Rightarrow \qquad \lambda_1,\ldots,\lambda_n$\\
Determining eigenvectors (for each $\lambda_i$): $(A-\lambda_i I) \cdot v_i=0\qquad \Rightarrow \qquad v_1,\ldots,v_n$\\

\subsection{FDM for Elliptic PDEs (Poisson: $-\Delta u = f$)}
%Dirichlet Boundary Conditions ($u(x,y)= f(x,y) \forall (x,y)\epsilon \delta G)$\\

Equation:    $-\Delta u(x,y)= f(x,y) \qquad
-\Delta u(x,y) = -\left(\frac{g(x+\Delta x,y ) -2 g(x,y)+ g(x-\Delta x,y)}{2\Delta x} +
\frac{g(x,y+\Delta y) -2 g(x,y)+ g(x,y-\Delta y)}{2\Delta y}\right)$\\

$h=\Delta x = \Delta y \Rightarrow \boxed{-\frac 1 {h^2} (\tilde{u}_{j,k+1} +
\tilde{u}_{j+1,k} + \tilde{u}_{j,k-1} + \tilde{u}_{j-1,k} - 4 \tilde{u}_{j,k})
= f_{j, k}}$\\[0.4cm]


$B \tilde{u} = f \Rightarrow B= \begin{bmatrix}
             T& D & 0 & \ldots \\
             D& T & D & \ldots \\
              0& D & T & \ldots \\
              0& 0 & D & \ldots \\
             \ldots
           \end{bmatrix}$
where $T=\frac{1}{h^2}\begin{bmatrix}
             4& -1 & 0 & \ldots \\
             -1& 4 & -1 & \ldots \\
              0& -1 & 4 & \ldots \\
              0& 0 & -1 & \ldots \\
             \ldots
           \end{bmatrix}$
and $D=\frac{1}{h^2}\begin{bmatrix}
             -1& 0& 0 & \ldots \\
             0 & -1 &  & \ldots \\
              0& 0&-1 & \ldots \\
             \ldots
           \end{bmatrix}$\\
   $\tilde{u}=\begin{bmatrix}
                \tilde{u}_{1,1}\\
                \tilde{u}_{2,1}\\
                \vdots\\
                \tilde{u}_{1,2}\\
                \tilde{u}_{2,2}\\
                \vdots
              \end{bmatrix}$
    $f=\begin{bmatrix}
               f_{1,1}\\
               f_{2,1}\\
               \vdots\\
               f_{1,2}\\
               f_{2,2}\\
               \vdots
             \end{bmatrix} +
             \frac{1}{h^2}\begin{bmatrix}
                u(0,0) + u(1,0) + u(0,1)\\
                u(2,0)\\
                \vdots\\
                u(0,2)\\
                0\\
                \vdots
              \end{bmatrix}$ \\
   Boundary conditions must be incorporated into $f$ if $u(x,y) \neq 0$ on $\partial\Omega$

\subsubsection{Irregular Grid (for the Boundary)}
\begin{minipage}{3cm}
	\includegraphics[width=3cm]{Content/02_numerics/irregulaereGitter.png}
\end{minipage}
\hfill
\begin{minipage}{14cm}

$- \frac{2}{h^2} \cdot \left(\frac{u(x+e \cdot h,y)-u(x,y)}{e(e+w)} +\frac{u(x-w \cdot h,y)-u(x,y)}{w(e+w)}+\frac{u(x,y+n \cdot h)-u(x,y)}{n(n+s)} + \frac{u(x,y-s \cdot h)-u(x,y)}{s(n+s)}\right)=f(x,y)$\\
\\
or\\
\\
$- \frac{2}{h^2} \cdot \left(\frac{u(P_E) - u(P)}{e(e+w)} + \frac{u(P_W) - u(P)}{w(e+w)} + \frac{u(P_N) - u(P)}{n(n+s)} + \frac{u(P_S) - u(P)}{s(n+s)}\right) = f(x,y)$\\
\\
If $\Delta x, \Delta y$ are constant ($w \cdot h = e \cdot h,\, n \cdot h = s \cdot h$) and $h=1$:\\
\\
$-\left(\frac{u(P_E) + u(P_W) - 2 u(P)}{\Delta x^2} + \frac{u(P_N) + u(P_S) - 2 u(P)}{\Delta y^2}\right) = f(x,y)$\\

\end{minipage}
\subsubsection{Neumann Boundary
%$\partial_n u(x,y) \forall (x,y) \epsilon \partial_n G$
}
\begin{minipage}{4cm}
	\includegraphics[width=4cm]{Content/02_numerics/NeumannRand.png}
\end{minipage}
\hfill
\begin{minipage}{14cm}
For Neumann boundary conditions, the boundary points must also be calculated.
In the figure, $P$, $P_N$, and $P_S$ are on the boundary,
$P_E$ is inside, and $P_W$ is outside of $\Omega$.
The Neumann boundary condition in $P$ is given: $\boxed{\partFrac{u}{n}(P)=g(P)}$\\
From the derivative $u_x(P) = \partFrac{u}{n}(P) = \frac{u(P_E)-u(P_W)}{2h}$,
the outside point $u(P_W)$ can be calculated: $u(P_W)=u(P_E)-2h\cdot u_x(P)$.
Thus, it holds:

$\boxed{\frac{2u(P_E) + u(P_N) +
u(P_S)- 4 u(P) - 2h\cdot u_x(P)}{h^2}}$\\

If $P_W$ and $P_E$ are swapped, the sign is reversed:
$u(P_W)=u(P_E)+2h\cdot u_x(P)$.\\

\textbf{Mirror Method}:\\
If $u_x(x,y) = 0$, it is also referred to as the mirror method. Points $P_W$ and $P_E$ then have the same value ($P_W=P_E$).
\end{minipage}


\subsection{FDM for Parabolic PDEs}
Heat conduction equation: $\boxed{u_t(x,t)=u_{xx}(x,t)}$\qquad $f(0)=f(1)=0$ \qquad$ \overset{\_}{\Omega}=[0,1]\times [0,\infty]$\\

Boundary conditions: $u(x,0)=f(x) \qquad u(0,t)=u(1,t)=0\qquad x\in(0,1) \qquad t\in[0,\infty)$

\newpage

\subsubsection{Explicit Method (Richardson Method)}
$\boxed{\frac{\tilde{u}(x,t+\Delta t) - \tilde{u}(x,t)}{\Delta t} =
\frac{\tilde{u}(x+\Delta x, t)-2\tilde{u}(x,y) + \tilde{u}( x - \Delta x, t )} {\Delta x^2}} \qquad \Delta x=\frac{1}{n} \qquad \Delta t=\frac{r}{n^2} \qquad \boxed{r=\frac{\Delta
t}{\Delta x^2}}$\\

\textbf{Idea:} From positions $k$, calculate $k+1$: $\tilde{u}_{j,k+1} = r \tilde{u}_{j-1,k} + (1-2r)\tilde{u}_{j,k} + r \tilde{u}_{j+1,k}$\\
Discretization of $t$: $k, k+1, \ldots$\\
Discretization of $x$: $j, j+1, \ldots$\\

\begin{itemize}
\item Initialization, boundary condition: $\tilde{u}_{j,0}=f(j/n)$ \qquad $\tilde{u}_{0,k}=\tilde{u}_{n,k}=0$
\item Approximation matrix: $C^{(n)}=\tridiag_{n-1}(r,1-2r,r)=\begin{bmatrix}
1-2r& r		& 0		& 0 	&\cdots\\
r	& 1-2r  & r		& 0		&\cdots\\
0	& r		& 1-2r 	& r 	&\cdots\\
0	& 0		& r		& 1-2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots
\end{bmatrix}$
\item Calculate one step: $\tilde{u}^{(k+1)}=C^{(n)} \tilde{u}^{(k)}$
\item Calculate $k$ steps: $\tilde{u}^{(k)}=\big\{C^{(n)}\big\}^k \tilde{u}^{(0)}$
\end{itemize}

\textbf{Convergence Behavior:} \\

\begin{minipage}{6cm}
\includegraphics[width=6cm]{Content/02_numerics/KonvExplizit.png}
\end{minipage}
\hfill
\begin{minipage}{12cm}
The method is stable if: $||C^{(n)}|| < 1 \qquad \Rightarrow\qquad r < \frac{1}{2}$\\

This requires very small time steps, making the method impractical due to high computational capacity needs.\\

The reason for the poor convergence behavior can be visualized geometrically. The calculation of the value at node $P$ includes the values of all nodes shaded in black. Only the 0-th level of the boundary values is considered.
\end{minipage}
To calculate the method with $C^k$ for $k$ steps, the red values (left and right) must be set to 0 (Boundary Condition).
For the boundary vector $\tilde{u}^{(0)}$, only the lowest black 7 points are filled in.


\subsubsection{Implicit Method}
In contrast to the explicit method, which uses values from the previous time step, here a system of equations is solved globally.\\

$\boxed{\frac{\tilde{u}(x,t) - \tilde{u}(x,t -\Delta t)}{\Delta t} =
\frac{\tilde{u}(x+\Delta x, t)-2\tilde{u}(x,y) + \tilde{u}( x - \Delta x, t )} {\Delta x^2}}
 \qquad \Delta x=\frac{1}{n} \qquad \Delta t=\frac{r}{n^2} \qquad \boxed{r=\frac{\Delta
t}{\Delta x^2}}$\\

$ \tilde{u}_{j,k} = - r \tilde{u}_{j-1,k+1} + (1+2r)\tilde{u}_{j,k+1} - r \tilde{u}_{j+1,k+1}$

\textbf{Idea:} Calculate derivatives using backward differences\\


\begin{itemize}
\item Initialization, boundary condition: $\tilde{u}_{j,0}=f(j/n)$ \qquad $\tilde{u}_{0,k}=\tilde{u}_{n,k}=0$
\item Approximation matrix: $E^{(n)}=\tridiag_{n-1}(-r,1+2r,-r)=\begin{bmatrix}
1+2r& -r		& 0		& 0 	&\cdots\\
-r	& 1+2r  & -r	& 0		&\cdots\\
0	& -r	& 1+2r 	& -r 	&\cdots\\
0	& 0		& -r	& 1+2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots
\end{bmatrix}$
\item Equation: $\tilde{u}^{(k)}=E^{(n)} \cdot \tilde{u}^{(k + 1)}$
\item Calculate one step: $\tilde{u}^{(k+1)}=\left\{E^{(n)}\right\}^{-1} \tilde{u}^{(k)}$
\item Calculate $k$ steps: $\tilde{u}^{(k)}=\left\{E^{(n)}\right\}^{\bm{-}k} \tilde{u}^{(0)}$
\end{itemize}

\textbf{Advantage:} The implicit method is always stable, regardless of the time resolution $\Delta t$\\
\textbf{Disadvantage:} Requires expensive matrix inversion.


\subsubsection{Crank-Nicolson Method (Mixed Method)}

The idea of the Crank-Nicolson method is to average the two approximations

$\boxed{\frac{\tilde{u}(x,t+\Delta t) - \tilde{u}(x,t)}{\Delta t} =
\frac{\tilde{u}(x+\Delta x, t)-2\tilde{u}(x,t) + \tilde{u}( x - \Delta x, t )} {\Delta x^2}}$\\
$\boxed{\frac{\tilde{u}(x,t+\Delta t) - \tilde{u}(x,t)}{\Delta t} =
\frac{\tilde{u}(x+\Delta x, t+\Delta t)-2\tilde{u}(x,t+\Delta t) + \tilde{u}( x - \Delta x, t +\Delta t)} {\Delta x^2}}$

With this idea, the continuous problem is transformed into the following discrete problem:

$-r \tilde{u}_{j-1,k+1} + (2+2r)\tilde{u}_{j,k+1} - r \tilde{u}_{j+1,k+1} = r
\tilde{u}_{j-1,k} + (2-2r)\tilde{u}_{j,k} + r \tilde{u}_{j+1,k} $

As with the other methods: $\Delta x=\frac{1}{n} \qquad \Delta t=\frac{r}{n^2} \qquad \boxed{r=\frac{\Delta
t}{\Delta x^2}}$
\begin{itemize}
\item Initialization, boundary condition: $\tilde{u}_{j,0}=f(j/n)$ \qquad $\tilde{u}_{0,k}=\tilde{u}_{n,k}=0$
\item Approximation matrices:\\
$F^{(n)}=E^{(n)}+I=\tridiag_{n-1}(-r,2+2r,-r)=\begin{bmatrix}
2+2r& -r	& 0		& 0 	&\cdots\\
-r	& 2+2r  & -r	& 0		&\cdots\\
0	& -r	& 2+2r 	& -r 	&\cdots\\
0	& 0		& -r	& 2+2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots
\end{bmatrix}$\\
$G^{(n)}=C^{(n)}+I=\tridiag_{n-1}(~r,~2-2r,~r~)=\begin{bmatrix}
2-2r& r		& 0		& 0 	&\cdots\\
r	& 2-2r  & r		& 0		&\cdots\\
0	& r		& 2-2r 	& r 	&\cdots\\
0	& 0		& r		& 2-2r 	&\cdots\\
\vdots&	\vdots&\vdots&\vdots&\ddots
\end{bmatrix}$
\item Equation: $F^{(n)} \cdot \tilde{u}^{(k+1)}=G^{(n)} \cdot \tilde{u}^{(k)}$
\item Calculate one step: $\tilde{u}^{(k+1)}=\left\{F^{(n)}\right\}^{-1} \cdot G^{(n)}\cdot \tilde{u}^{(k)}$
\item Calculate $k$ steps: $\tilde{u}^{(k)}=\left(\left\{F^{(n)}\right\}^{-1} \cdot G^{(n)}\right)^{k}\cdot \tilde{u}^{(0)}$
\end{itemize}


\subsection{FDM for Hyperbolic PDEs}

\begin{minipage}{8cm}
$u_{tt}=u_{xx} \rightarrow \text{homogeneous}$\\
$u_{tt} -u_{xx}= v(x,t) \rightarrow \text{inhomogeneous}$
\end{minipage}
\begin{minipage}{5cm}
Initial conditions:\\
$u(x,0)=f(x) \quad u_t(x,0)=g(x)$
\end{minipage}\\

\subsubsection{Leap-Frog Scheme}
$\tilde{u}_{j,k+1}=r^2 \tilde{u}_{j-1,k} + 2(1-r^2)\tilde{u}_{j,k}+ r^2
\tilde{u}_{j+1,k}-\tilde{u}_{j,k-1} \qquad r = \frac{\Delta t}{\Delta x}$\\
\\
$\tilde{u}_{j,0} = f(j\Delta x) \qquad \tilde{u}_{j,1}= f(j\Delta x) + g(j\Delta x)\Delta t + f''(j \Delta x) \frac{\Delta t^2}{2} $\\

\subsubsection{Transport Equation}
$$u_x(x,t) + u_t(x, t) = 0 \qquad u(x,0)=f(x) \longrightarrow u(x,t)=f(x-t)$$

\subparagraph{Downwind Scheme}
$$\frac{\tilde{u}(x,t+\Delta t)-\tilde{u}(x,t)}{\Delta t} + \frac{\tilde{u}(x + \Delta x,t) - \tilde{u}(x, t)}{\Delta x} = 0 \qquad
\tilde{u}_{j,k+1}=(1+r)\tilde{u}_{j,k} - r\tilde{u}_{j+1,k} \quad r=\frac{\Delta t}{\Delta x} \quad \text{Mostly Divergent}$$

\subparagraph{Upwind Scheme}
$$\frac{\tilde{u}(x,t+\Delta t)-\tilde{u}(x,t)}{\Delta t} + \frac{\tilde{u}(x,t) - \tilde{u}(x-\Delta x,
t)}{\Delta x} = 0 \qquad
\tilde{u}_{j,k+1}=(1-r)\tilde{u}_{j,k} + r\tilde{u}_{j-1,k} \quad \text{Convergent for} \quad r=\frac{\Delta t}{\Delta x} \leq 1$$

\subparagraph{Centered Scheme}
$$\frac{\tilde{u}(x,t+\Delta t)-\tilde{u}(x,t)}{\Delta t} + \frac{\tilde{u}(x + \Delta x,t) - \tilde{u}(x - \Delta x, t)}{2 \Delta x} = 0 \qquad
\tilde{u}_{j,k+1}= - \frac{r}{2}\tilde{u}_{j+1,k} + \tilde{u}_{j,k} + \frac{r}{2}\tilde{u}_{j-1,k} \quad r=\frac{\Delta t}{\Delta x} $$

\subparagraph{Lax-Wendroff Scheme}
$$\tilde{u}_{j,k+1}=  A\tilde{u}_{j+1,k} + B \tilde{u}_{j,k} + C \tilde{u}_{j-1,k} \quad r=\frac{\Delta t}{\Delta x} \quad A = \frac{r^2 - r}{2} \quad B = 1- r^2 \quad C= \frac{r^2 +r}{2}$$

\subsection{FVM (Finite Volume Method, Voronoi's Method)}
$\Delta u=0$\qquad in \quad$\Omega$\\
$u(x,y)=f(x,y)$ \qquad on \quad$\partial\Omega$\\
Gauss's theorem states: $\boxed{\oint\limits_{\Gamma}{\Delta u(x,y) dx dy}=\int\limits_{\Gamma}{\mathrm{div}~\mathrm{grad}~ u(x,y) dx dy}=\oint\limits_{\partial\Gamma}{\mathrm{grad}~ u(x,y) d\vec{n}}}$\\

Where the boundary normal vector $\vec{n}$ is always directed perpendicular to the outer region $\Gamma$.\\

$\Rightarrow$ $\oint\limits_{\Gamma}{\Delta u(x,y) dx dy}=\oint\limits_{\partial\Gamma}{\mathrm{grad}~ u(x,y) d\vec{n}}=0$

\begin{minipage}{4cm}
	\includegraphics[width=4cm]{Content/02_numerics/FVMPrinzip.png}
\end{minipage}
\hfill
\begin{minipage}{14cm}
	$\frac{u(P_E)-u(P_P)}{h}\cdot h+\frac{u(P_N)-u(P_P)}{h}\cdot h+\frac{u(P_W)-u(P_P)}{h}\cdot h+\frac{u(P_S)-u(P_P)}{h}\cdot h\approx 0$\\

	$\Rightarrow\tilde{u}(P_E)+\tilde{u}(P_N)+\tilde{u}(P_W)+\tilde{u}(P_S)-4\cdot\tilde{u}(P_P)=0$
\end{minipage}

\textbf{Advantages:}\\
\begin{itemize}
\item Allows computation with flow quantities and balances, thus avoiding the Laplace operator $(\Delta)$ and the associated complex mathematics.
\item Can handle complicated geometries.
\end{itemize}

\begin{minipage}{6cm}
	\includegraphics[width=6cm]{Content/02_numerics/FVM1.png}
\end{minipage}
\hfill
\begin{minipage}{12cm}
\textbf{Procedure for Calculation:}\\
\begin{enumerate}
\item Choose points $P_1,\ldots,P_n$.
\item Divide the region into small subregions, e.g., by bisecting perpendiculars.
\item Discretize the boundary.\\
\end{enumerate}

For $P_i$ cell: $\sum\limits_{j} \dfrac{u(P_{i,j}) - u(P_i)}{\delta_{i,j}} \cdot \lambda_{i,j} = 0$

For P1 cell:\quad $\frac{\tilde{u}(P_2)-\tilde{u}(P_1)}{\delta_{1,2}}\cdot\lambda_{1,2}+\frac{\tilde{u}(P_3)-\tilde{u}(P_1)}{\delta_{1,3}}\cdot\lambda_{1,3}+\frac{\tilde{u}(R_1)-\tilde{u}(P_1)}{\delta_1}\cdot\lambda_1=0$\\

For P2 cell:\quad $\frac{\tilde{u}(P_1)-\tilde{u}(P_2)}{\delta_{1,2}}\cdot\lambda_{1,2}+\frac{\tilde{u}(P_3)-\tilde{u}(P_2)}{\delta_{2,3}}\cdot\lambda_{2,3}+\frac{\tilde{u}(R_2)-\tilde{u}(P_2)}{\delta_2}\cdot\lambda_2=0$\\

For P3 cell:\quad $\frac{\tilde{u}(P_2)-\tilde{u}(P_3)}{\delta_{2,3}}\cdot\lambda_{2,3}+\frac{\tilde{u}(P_1)-\tilde{u}(P_3)}{\delta_{1,3}}\cdot\lambda_{1,3}+\frac{\tilde{u}(R_3)-\tilde{u}(P_3)}{\delta_3}\cdot\lambda_3=0$\\
\end{minipage}

\begin{minipage}{6cm}
	\includegraphics[width=6cm]{Content/02_numerics/FVM2.png}
\end{minipage}
\hfill
\begin{minipage}{12cm}

 $\frac{\tilde{u}(P_E)-\tilde{u}(P_N)}{1/4\cdot\sqrt{2}}\cdot\frac{\sqrt{2}}{2}+\frac{\tilde{u}(P_W)-\tilde{u}(P_N)}{1/4\cdot\sqrt{2}}\cdot\frac{\sqrt{2}}{2}+\frac{\tilde{u}(R_N)-\tilde{u}(P_N)}{1/4}\cdot 1=0$\\

 $(\tilde{u}_E-\tilde{u}_N)\cdot 2 + (\tilde{u}_W-\tilde{u}_N)\cdot 2 + (1/2-\tilde{u}_N)\cdot 4=0$\\

 $0\cdot\tilde{u}_S+2\cdot\tilde{u}_E+2\cdot\tilde{u}_W-8\cdot\tilde{u}_N+2=0$

\end{minipage}

\begin{minipage}{6cm}
\includegraphics[width=6cm]{Content/02_numerics/fvm_beispiel.pdf}
\end{minipage}
\hfill
\begin{minipage}{12cm}

u1: $\frac{u(b_1) - u(p_1)}{h/2} \cdot h + \frac{u(b_2) - u(p_1)}{h/2} \cdot h +
\frac{u(b_3) - u(p_1)}{h/2} \cdot s_2 + \frac{u(p_2) - u(p_1)}{h} \cdot s_1 $\\
\colorbox{yellow}{Caution for quick calculations: $\frac{u(b_2) - u(p_1)}{h/2}
\cdot h = (u(b_2) - u(p_1)) \cdot 2$}

\end{minipage}


example with $\Delta u(x,y) \neq 0$ and two voronoi points: \\
The function $u(x,y)$ is defined on the square $\Omega =[0,3]\times [0,3]$.
The function $u(x,y)$ satisfies in $\Omega$ $$  \Delta u(x,y)+4=0 $$ and $u(x,y)=0$ on the
boundary of $\Omega$. Determine approximate values for $u(1,1)$ and $u(2,2)$.
Use finite volumes à la Voronoi with Voronoi-points $(1,1)$ and $(2,2)$

\begin{minipage}{6cm}
  \begin{tikzpicture}

    \draw[thick,-latex] (0,0) -- (3.3,0) node[anchor=north](){${x}$};
    \draw[thick,-latex] (0,0) -- (0,3.3) node[anchor= west](){${y}$};


    \foreach \x in {0,1,...,3}  {   % for x-axis
      \draw [] (\x,0) -- (\x,-0.1) node[anchor=north](){0};
      \draw [] (0,\x) -- (-0.1,\x)  node[anchor=east](){0};
      \node[anchor=center] () at (\x,0) {\textbullet};
      \node[anchor=center] () at (0, \x) {\textbullet};
      \node[anchor=center] () at (3, \x) {\textbullet};
      \node[anchor=center] () at (\x, 3) {\textbullet};
    }


    \node[anchor=center, red] () at (1, 1) {\textbullet};
    \node[anchor=center, red] () at (2, 2) {\textbullet};
    \node[anchor=west, red] () at (1, 1) {$\tilde u_1$};
    \node[anchor=east, red] () at (2, 2) {$\tilde u_2$};

    \draw[green, thick] (1, 1) -- (2, 2);
    \draw[red, thick] (0, 0) -- (0, 3);
    \draw[red, thick] (0, 0) -- (3, 0);
    \draw[red, thick] (3, 0) -- (3, 3);
    \draw[red, thick] (0, 3) -- (3, 3);
    \draw[blue, thick] (1,1) -- (0,1);
    \draw[blue, thick] (2,2) -- (3,2);
    \draw[green, thick] (0,3) -- (3,0);


  \end{tikzpicture}

\end{minipage}
\hfill
\begin{minipage}{12cm}
$$ \frac{1}{2} \int_{0}^{3} \int_{0}^{3} -4 \,dxdy = -18 $$
Function integrated over the voronoi cell example 68 in the script
$$
\frac{0-\tilde u_1}{\textcolor{blue}{1}} \textcolor{red}{6} + \frac{\tilde u_2  -\tilde u_1}{\textcolor{green}{\sqrt{2}}} \textcolor{green}{3\sqrt{2}} = -18
$$
$$
\frac{0-\tilde u_2}{\textcolor{blue}{1}} \textcolor{red}{6} + \frac{\tilde u_1 -\tilde u_2}{\textcolor{green}{\sqrt{2}}} \textcolor{green}{3\sqrt{2}} = -18$$

$$ A = \begin{bmatrix}
-9 &  3\\
3 & -9
\end{bmatrix} \begin{pmatrix}
\tilde u_1 \\
\tilde u_2
\end{pmatrix}= \begin{pmatrix}
-18 \\
-18
\end{pmatrix}
$$

\end{minipage}


\input{Content/02_numerics/FEM}
